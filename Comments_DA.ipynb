{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "df = pd.read_csv('Snappfood.csv', encoding='utf-8', on_bad_lines='skip', header=None)\n",
    "\n",
    "split_columns = df[0].str.split('\\t', n=2, expand=True)\n",
    "split_columns.columns = ['label_id', 'comment', 'label']\n",
    "\n",
    "for col in split_columns.columns:\n",
    "    split_columns[col] = split_columns[col].str.replace('\\t', '', regex=False)\n",
    "\n",
    "\n",
    "split_columns = split_columns.drop(index=0).reset_index(drop=True)\n",
    "clean_df = split_columns\n",
    "clean_df.to_csv('Snappfood_clean.csv', index=False)\n",
    "saved_df = pd.read_csv('Snappfood_clean.csv')\n",
    "saved_df[['label', 'label_id']] = saved_df['label'].str.extract(r'([A-Z]+)(\\d)')\n",
    "saved_df.to_csv('Snappfood_final.csv', index=False)\n",
    "snap_comments = pd.read_csv('Snappfood_final.csv')\n",
    "\n",
    "def split_words(comments):\n",
    "    words = comments.split()\n",
    "    return [f\"'{word}'\" for word in words]\n",
    "saved_df['words'] = saved_df['comment'].apply(split_words)\n",
    "all_words = saved_df['words'].explode()\n",
    "# print(type(all_words))\n",
    "# print('len all_words:')\n",
    "# print(len(all_words))\n",
    "# print('*'* 50)\n",
    "\n",
    "stop_words = set([\n",
    "\n",
    "    '!', 'و', 'بود','\"اصلا\"\"','به','از','بود.','خیلی','هم','که','با','ولی','در','فقط','این',\n",
    "    'شده','رو','همیشه','رسید','من','واقعا','همه','مثل','بسیار','بود،','اما','به','تا',\n",
    "    'بودم','اینکه','داشت','بودن','برای','یک','تو','دیگه','داده','دادم','بعد','به','تا','یه','را'\n",
    "])\n",
    "\n",
    "def create_word_label_df(comments, label):\n",
    "    words = []\n",
    "    for comment in comments:\n",
    "        filtered_words = [word for word in comment.split() if word.lower() not in stop_words]\n",
    "        words.extend(filtered_words)\n",
    "    return pd.DataFrame({'word': words, 'label': label})\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "total_length_all = all_words.str.len().sum()\n",
    "print(f\"Total length of all words in all comments: {total_length_all}\")\n",
    "\n",
    "happy_comments = (snap_comments[snap_comments['label'] == 'HAPPY']['comment']).apply(split_words)\n",
    "all_happy_words = [word for words_list in happy_comments for word in words_list]\n",
    "lengths_happy = [len(word) for word in all_happy_words]\n",
    "total_length_happy = sum(lengths_happy)\n",
    "print(f\"Total length of all words in HAPPY comments: {total_length_happy}\")\n",
    "\n",
    "\n",
    "sad_comments = (snap_comments[snap_comments['label'] == 'SAD']['comment']).apply(split_words)\n",
    "all_sad_words = [word for words_list in sad_comments for word in words_list]\n",
    "lengths_sad = [len(word) for word in all_sad_words]\n",
    "total_length_sad = sum(lengths_sad)\n",
    "print(f\"Total length of all words in SAD comments: {total_length_sad}\")\n",
    "\n",
    "\n",
    "\n",
    "happy_df = create_word_label_df(snap_comments[snap_comments['label'] == 'HAPPY']['comment'], 'HAPPY')\n",
    "sad_df = create_word_label_df(snap_comments[snap_comments['label'] == 'SAD']['comment'], 'SAD')\n",
    "combined_df = pd.concat([happy_df, sad_df])\n",
    "word_counts = pd.crosstab(index=combined_df['word'], columns=combined_df['label'])\n",
    "\n",
    "happy_words_sorted = word_counts['HAPPY'].sort_values(ascending=False)\n",
    "sad_words_sorted = word_counts['SAD'].sort_values(ascending=False)\n",
    "print('*' * 50)\n",
    "print(\"Most common words in HAPPY comments:\")\n",
    "happy = happy_words_sorted[happy_words_sorted > 0].head(50)\n",
    "print(happy)\n",
    "print('*' * 50)\n",
    "print(\"\\nMost common words in SAD comments:\")\n",
    "sad = sad_words_sorted[sad_words_sorted > 0].head(50)\n",
    "print(sad)\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-21T05:51:07.237119Z",
     "start_time": "2025-05-21T05:51:07.083432Z"
    }
   },
   "cell_type": "code",
   "source": [
    "drop_duplicated = all_words.drop_duplicates()\n",
    "print(drop_duplicated)\n"
   ],
   "id": "246fbe5a8dfd77ea",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0            'واقعا'\n",
      "0              'حیف'\n",
      "0              'وقت'\n",
      "0               'که'\n",
      "0           'بنویسم'\n",
      "            ...     \n",
      "69732     'دارم!!!؟'\n",
      "69735     'عااااشقش'\n",
      "69743    'تعجبه!!!!'\n",
      "69743     'دورریختن'\n",
      "69748      'چربی‌اش'\n",
      "Name: words, Length: 46433, dtype: object\n",
      "46433\n"
     ]
    }
   ],
   "execution_count": 83
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-21T03:26:12.069299Z",
     "start_time": "2025-05-21T03:26:12.066581Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "b686ef33b35c02aa",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T06:39:05.889672Z",
     "start_time": "2025-05-20T06:39:05.887841Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "efcf4211c1669a0e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "5c48c91bea091091"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
